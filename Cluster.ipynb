{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"LOCF Development and Cluster Analysis\"\n",
        "ownership: \"Tyler Technologies\"\n",
        "author: \"Daniel J Fasteen, Ph.D.\"\n",
        "topic: \"AVM Analysis\"\n",
        "date: \"2/28/2025\"\n",
        "format:\n",
        "  html:\n",
        "    embed-resources: true        # bundles Folium map\n",
        "    smooth-scroll: true\n",
        "    fontcolor: black\n",
        "    toc: true\n",
        "    toc-location: right\n",
        "    toc-depth: 2\n",
        "    code-fold: true    \n",
        "    code-fold-show: false\n",
        "resources: [locf_map.html]       # make sure the map ships with the doc\n",
        "---\n",
        "\n",
        "### Instantiate libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "from branca.colormap import StepColormap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data file from GWR Analysis\n",
        "Load the data from the analysis performed from the other notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| \n",
        "file_path = \"Data/moddat_gwr.csv\"\n",
        "\n",
        "# Load the CSV file\n",
        "moddatgwr_dfa = pd.read_csv(file_path, low_memory=False)\n",
        "\n",
        "# Check if the data loaded correctly\n",
        "#print(moddatgwr_dfa) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summarize Sales Data to find the Average Property in the Study Area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "# If moddatgwr is still a GeoDataFrame, drop geometry for now\n",
        "\n",
        "moddatgwr_df = (\n",
        "    moddatgwr_dfa\n",
        "      .copy()\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "if isinstance(moddatgwr_df, gpd.GeoDataFrame):\n",
        "    moddatgwr_df = moddatgwr_df.drop(columns=moddatgwr_df.geometry.name)\n",
        "\n",
        "# Add an INTERCEPT column (=1 for every row)\n",
        "moddatgwr_df[\"INTERCEPT\"] = 1\n",
        "\n",
        "# Attribute list (keep order identical to X matrix construction)\n",
        "attributes = [\n",
        "    \"LANDVAL\", \"GRDFACT\", \"TLA\", \"RMOS\", \"EFFAGE\",\n",
        "    \"POOL_AREA\", \"ATTGAR_AREA\", \"DETGARAGE_AREA\", \"TOTPORCH\",\n",
        "    \"STHT2\", \"AGEMAX60\", \"SEG_OTHER\", \"CARPRT_AREA\", \"INTERCEPT\"\n",
        "]\n",
        "\n",
        "def nz(series):\n",
        "    \"\"\"Return series with zeros removed (for min/max/mean/median).\"\"\"\n",
        "    return series.loc[series.ne(0)]\n",
        "\n",
        "summary_stats = (\n",
        "    moddatgwr_df[attributes]\n",
        "      .agg([\"count\", lambda s: nz(s).min(), lambda s: nz(s).max(),\n",
        "            lambda s: nz(s).mean(), lambda s: nz(s).median()])\n",
        "      .T\n",
        "      .reset_index()\n",
        ")\n",
        "summary_stats.columns = [\"Variable\", \"count\", \"min\", \"max\", \"mean\", \"median\"]\n",
        "summary_stats.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract GWR Coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "coef_cols = [\n",
        "    \"INTERCEPT\", \"LANDVAL_B\", \"GRDFACT_B\", \"TLA_B\", \"RMOS_B\", \"EFFAGE_B\",\n",
        "    \"POOL_AREA_B\", \"ATTGAR_AREA_B\", \"DETGARAGE_AREA_B\", \"TOTPORCH_B\",\n",
        "    \"STHT2_B\", \"AGEMAX60_B\", \"SEG_OTHER_B\", \"CARPRT_AREA_B\"\n",
        "]\n",
        "\n",
        "gt_coefficients = (\n",
        "    moddatgwr_df\n",
        "      .loc[:, [\"QUICKREFID\", \"MASMT\"] + coef_cols]\n",
        "      .head()\n",
        ")\n",
        "gt_coefficients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Location Factor Development\n",
        "This analysis can be performed on both sales and subjects to get the average property to use for MBV. \n",
        "\n",
        "## Build MBV and LOCF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "# Mapping: feature → column containing its local GWR coefficient\n",
        "feature_coef = {\n",
        "    \"INTERCEPT\"       : \"Intercept_B\",\n",
        "    \"GRDFACT\"         : \"GRDFACT_B\",\n",
        "    \"RMOS\"            : \"RMOS_B\",\n",
        "    \"LANDVAL\"         : \"LANDVAL_B\",\n",
        "    \"TLA\"             : \"TLA_B\",\n",
        "    \"EFFAGE\"          : \"EFFAGE_B\",\n",
        "    \"POOL_AREA\"       : \"POOL_AREA_B\",\n",
        "    \"ATTGAR_AREA\"     : \"ATTGAR_AREA_B\",\n",
        "    \"DETGARAGE_AREA\"  : \"DETGARAGE_AREA_B\",\n",
        "    \"TOTPORCH\"        : \"TOTPORCH_B\",\n",
        "    \"AGEMAX60\"        : \"AGEMAX60_B\",\n",
        "    \"SEG_OTHER\"       : \"SEG_OTHER_B\",\n",
        "    \"CARPRT_AREA\"     : \"CARPRT_AREA_B\"\n",
        "}\n",
        "\n",
        "# ---- mean values from summary_stats ---------------------------\n",
        "means = (\n",
        "    summary_stats\n",
        "      .set_index(\"Variable\")[\"mean\"]\n",
        "      .to_dict()\n",
        ")\n",
        "\n",
        "# ---- contribution columns -------------------------------------\n",
        "for feat, coef_col in feature_coef.items():\n",
        "    if feat in means and coef_col in moddatgwr_df.columns:\n",
        "        moddatgwr_df[f\"{feat}_Contribution\"] = means[feat] * moddatgwr_df[coef_col]\n",
        "\n",
        "contrib_cols = [c for c in moddatgwr_df.columns if c.endswith(\"_Contribution\")]\n",
        "\n",
        "# ---- MBV, MBVavg, LOCF ----------------------------------------\n",
        "moddatgwr_df[\"MBVSUM\"] = moddatgwr_df[contrib_cols].sum(axis=1)\n",
        "mbv_avg                 = moddatgwr_df[\"MBVSUM\"].mean()\n",
        "moddatgwr_df[\"MBVAVG\"]  = mbv_avg\n",
        "moddatgwr_df[\"LOCF\"]    = moddatgwr_df[\"MBVSUM\"] / mbv_avg\n",
        "\n",
        "moddatgwr_df.loc[:, [\"UNIQUE\",\"QUICKREFID\", \"LOCF\", \"MBVSUM\"]].head() #+ contrib_cols].head()\n",
        "\n",
        "# Write to Excel as needed\n",
        "moddatgwr_df.to_excel(\"Analysis/moddatgwr_df.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Map LOCF across the Study Area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "results": "asis"
      },
      "source": [
        "#| label: build-locf-map\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "import folium\n",
        "import numpy as np\n",
        "from branca.colormap import linear\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Prepare data (as in your previous chunk)\n",
        "# ------------------------------------------------------------------\n",
        "plot_df = (\n",
        "    moddatgwr_df\n",
        "      .dropna(subset=[\"LOCF\", \"COORDLONGX\", \"COORDLATY\"])\n",
        "      .copy()\n",
        ")\n",
        "plot_df[\"LOCF\"] = plot_df[\"LOCF\"].round(4)\n",
        "\n",
        "lo_min, lo_max = plot_df[\"LOCF\"].min(), plot_df[\"LOCF\"].max()\n",
        "cmap = linear.RdYlBu_11.scale(lo_min, lo_max).to_step(11)\n",
        "cmap.caption = \"LOCF\"\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Build map\n",
        "# ------------------------------------------------------------------\n",
        "m = folium.Map(\n",
        "    location=[plot_df[\"COORDLATY\"].median(),\n",
        "              plot_df[\"COORDLONGX\"].median()],\n",
        "    zoom_start=10,\n",
        "    tiles=\"OpenStreetMap\"\n",
        ")\n",
        "\n",
        "for _, r in plot_df.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        [r[\"COORDLATY\"], r[\"COORDLONGX\"]],\n",
        "        radius=5,\n",
        "        color=\"black\", weight=1,\n",
        "        fill=True, fill_opacity=0.8,\n",
        "        fill_color=cmap(r[\"LOCF\"]),\n",
        "        popup=(f\"<b>QUICKREFID:</b> {r['QUICKREFID']}<br>\"\n",
        "               f\"<b>SEGCLASS:</b> {r['SEGCLASS']}<br>\"\n",
        "               f\"<b>LOCF:</b> {r['LOCF']}\")\n",
        "    ).add_to(m)\n",
        "\n",
        "cmap.add_to(m)\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cluster Analysis \n",
        "\n",
        "## Import Clustering Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Data For Clustering NBHDS\n",
        "\n",
        "Create a data frame for how you want to weight your analysis on. In this case SEGCLASS, MASMT, ACTAGE, and TLA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "#Mapping SEGCLASS to numeric values\n",
        "segclass_mapping = {\n",
        "    \"R1\": 1, \n",
        "    \"R2\": 2, \n",
        "    \"R3\": 3,\n",
        "    \"R4\": 4, \n",
        "    \"R5\": 5,\n",
        "    \"R6\": 6\n",
        "}\n",
        "\n",
        "moddatgwr_df[\"SEGCLASS_NUM\"] = moddatgwr_df[\"SEGCLASS\"].map(segclass_mapping)\n",
        "\n",
        "# Subset for clustering\n",
        "clustering_data = moddatgwr_df[[\"MASMT\", \"SEGCLASS_NUM\", \"ACTAGE\", \"TLA\"]].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and Scale Siholuettes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "clustering_data_scaled = scaler.fit_transform(clustering_data)\n",
        "\n",
        "# Compute the distance matrix\n",
        "dist_matrix = squareform(pdist(clustering_data_scaled, metric='euclidean'))\n",
        "\n",
        "# Perform hierarchical clustering using Ward's method\n",
        "hc = linkage(clustering_data_scaled, method='ward')\n",
        "\n",
        "# Plot silhouette scores for optimal cluster selection\n",
        "silhouette_scores = []\n",
        "for k in range(2, 11):  # Test cluster sizes from 2 to 10\n",
        "    clusters = fcluster(hc, k, criterion='maxclust')\n",
        "    score = silhouette_score(clustering_data_scaled, clusters)\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(2, 11), silhouette_scores, marker='o')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Method for Optimal Clusters')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Cluster Dendrograms for Potential Neighrbohood Clusters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(hc)\n",
        "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find the optimal number of Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Determine the number of clusters for different heights\n",
        "for h in range(5, 40):\n",
        "    clusters = fcluster(hc, h, criterion='distance')\n",
        "    print(f\"Height: {h} - Number of clusters: {len(set(clusters))}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Replot Dendrogram with Visual Dividers\n",
        "Dividers at h = 19 (k=13) and h=22 (k=9) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(hc)\n",
        "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.axhline(y=19, color='red', linestyle='--')  # threshold for clustering\n",
        "plt.axhline(y=22, color='green', linestyle='--')  #threshold for clustering\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cut into K Clusters and append to original dataset with summary \n",
        "Cutting into 13 clusters (h=19)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clust_df = (\n",
        "    moddatgwr_df\n",
        "      .copy()\n",
        ")\n",
        "\n",
        "# Assign clusters to the original dataset\n",
        "clust_df[\"nbhd_clust13\"] = fcluster(hc, 19, criterion='distance')\n",
        "\n",
        "# Compute summary statistics by cluster\n",
        "nbhd_summary = clust_df.groupby(\"nbhd_clust13\").agg(\n",
        "    n=(\"LANDVAL\", \"count\"),\n",
        "    \n",
        "    MIN_LOCF=(\"LOCF\", \"min\"), \n",
        "    MAX_LOCF=(\"LOCF\", \"max\"), \n",
        "    MEAN_LOCF=(\"LOCF\", \"mean\"), \n",
        "    MED_LOCF=(\"LOCF\", \"median\"), \n",
        "    SD_LOCF=(\"LOCF\", \"std\"),\n",
        "    \n",
        "    MIN_LND=(\"LANDVAL\", \"min\"), \n",
        "    MAX_LND=(\"LANDVAL\", \"max\"), \n",
        "    MEAN_LND=(\"LANDVAL\", \"mean\"), \n",
        "    MED_LND=(\"LANDVAL\", \"median\"), \n",
        "    SD_LND=(\"LANDVAL\", \"std\"),\n",
        "   \n",
        "    MIN_TOTALVAL=(\"MASMT\", \"min\"), \n",
        "    MAX_TOTALVAL=(\"MASMT\", \"max\"), \n",
        "    MEAN_TOTALVAL=(\"MASMT\", \"mean\"), \n",
        "    MED_TOTALVAL=(\"MASMT\", \"median\"), \n",
        "    SD_TOTALVAL=(\"MASMT\", \"std\"),\n",
        "    \n",
        "    MIN_TLA=(\"TLA\", \"min\"), \n",
        "    MAX_TLA=(\"TLA\", \"max\"), \n",
        "    MEAN_TLA=(\"TLA\", \"mean\"), \n",
        "    MED_TLA=(\"TLA\", \"median\"),\n",
        "    \n",
        "    MIN_AGE=(\"ACTAGE\", \"min\"), \n",
        "    MAX_AGE=(\"ACTAGE\", \"max\"), \n",
        "    MEAN_AGE=(\"ACTAGE\", \"mean\"), \n",
        "    MED_AGE=(\"ACTAGE\", \"median\"),\n",
        "\n",
        "    MIN_SEGCLASS=(\"SEGCLASS_NUM\", \"min\"), \n",
        "    MAX_SEGCLASS=(\"SEGCLASS_NUM\", \"max\"), \n",
        "    MEAN_SEGCLASS=(\"SEGCLASS_NUM\", \"mean\"), \n",
        "    MED_SEGCLASS=(\"SEGCLASS_NUM\", \"median\")\n",
        ").reset_index()\n",
        "\n",
        "# Display summary statistics\n",
        "print(nbhd_summary)\n",
        "\n",
        "# Write to Excel as needed\n",
        "#nbhd_summary.to_excel(\"Analysis/nbhd_summary.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Map New Clusters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "req_cols = {\"nbhd_clust13\", \"COORDLONGX\", \"COORDLATY\", \"QUICKREFID\"}\n",
        "missing  = req_cols - set(clust_df.columns)\n",
        "if missing:\n",
        "    raise KeyError(f\"Missing columns in clust_df: {missing}\")\n",
        "\n",
        "plot_df = clust_df.dropna(subset=[\"COORDLONGX\", \"COORDLATY\"]).copy()\n",
        "\n",
        "# ensure cluster labels are strings (safer for legend keys)\n",
        "plot_df[\"nbhd_clust13\"] = plot_df[\"nbhd_clust13\"].astype(str)\n",
        "\n",
        "clusters = sorted(plot_df[\"nbhd_clust13\"].unique())\n",
        "\n",
        "if len(clusters) != 13:\n",
        "    raise ValueError(f\"Expected 13 clusters but found {len(clusters)}: {clusters}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2  Define a 13-colour categorical palette\n",
        "#     (Set3 only has 12, so we extend with one extra colour)\n",
        "# ------------------------------------------------------------------\n",
        "palette_hex = [\n",
        "    \"#8dd3c7\", \"#ffffb3\", \"#bebada\", \"#fb8072\", \"#80b1d3\",\n",
        "    \"#fdb462\", \"#b3de69\", \"#fccde5\", \"#d9d9d9\", \"#bc80bd\",\n",
        "    \"#ccebc5\", \"#ffed6f\", \"#1f78b4\"          # 13th swatch\n",
        "]\n",
        "\n",
        "color_lookup = {cl: palette_hex[i] for i, cl in enumerate(clusters)}\n",
        "\n",
        "def colour(cl):\n",
        "    return color_lookup.get(cl, \"#666666\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3  Create Folium map centred on the data\n",
        "# ------------------------------------------------------------------\n",
        "center = [plot_df[\"COORDLATY\"].median(), plot_df[\"COORDLONGX\"].median()]\n",
        "m = folium.Map(location=center, zoom_start=11, tiles=\"OpenStreetMap\")\n",
        "\n",
        "for _, r in plot_df.iterrows():\n",
        "    popup = folium.Popup(\n",
        "        (f\"<b>QUICKREFID:</b> {r['QUICKREFID']}<br>\"\n",
        "         f\"<b>Cluster ID:</b> {r['nbhd_clust13']}\"),\n",
        "        max_width=250\n",
        "    )\n",
        "    folium.CircleMarker(\n",
        "        [r[\"COORDLATY\"], r[\"COORDLONGX\"]],\n",
        "        radius=5,\n",
        "        color=\"black\", weight=1,\n",
        "        fill=True, fill_opacity=0.85,\n",
        "        fill_color=colour(r[\"nbhd_clust13\"]),\n",
        "        popup=popup\n",
        "    ).add_to(m)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 4  Add a legend\n",
        "# ------------------------------------------------------------------\n",
        "legend_html = (\n",
        "    '<div style=\"position: fixed; bottom: 50px; left: 50px;'\n",
        "    ' background: white; z-index: 9999; font-size: 14px;'\n",
        "    ' border-radius: 8px; padding: 10px; box-shadow: 2px 2px 6px rgba(0,0,0,0.3);\">'\n",
        "    '<b>nbhd_clust13</b><br>'\n",
        ")\n",
        "for cl, col in color_lookup.items():\n",
        "    legend_html += (f'<i style=\"background:{col}; width:12px; height:12px;'\n",
        "                    ' display:inline-block; margin-right:5px;\"></i>'\n",
        "                    f'{cl}<br>')\n",
        "legend_html += '</div>'\n",
        "\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "# Return map → Quarto injects it inline\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------------------------------------------------------------\n",
        "\n",
        "# Cluster Aggregated NBHDS \n",
        "If you already have well defined NBHDS and want to define groupings for Market. We can aggregate LOCF by NBHD and build clusters that way. We can also cluster GWR R2 to see where model is performing well. Also cluster residuals as well. Use your best judgement in building Segments for the Hirearchy. \n",
        "\n",
        "## Neighrbohood Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute summary statistics by cluster\n",
        "actnbhd_summary = clust_df.groupby(\"NBHD\").agg(\n",
        "    n=(\"LANDVAL\", \"count\"),\n",
        "    \n",
        "    MIN_LOCF=(\"LOCF\", \"min\"), \n",
        "    MAX_LOCF=(\"LOCF\", \"max\"), \n",
        "    MEAN_LOCF=(\"LOCF\", \"mean\"), \n",
        "    MED_LOCF=(\"LOCF\", \"median\"), \n",
        "    SD_LOCF=(\"LOCF\", \"std\"),\n",
        "    \n",
        "    MIN_LND=(\"LANDVAL\", \"min\"), \n",
        "    MAX_LND=(\"LANDVAL\", \"max\"), \n",
        "    MEAN_LND=(\"LANDVAL\", \"mean\"), \n",
        "    MED_LND=(\"LANDVAL\", \"median\"), \n",
        "    SD_LND=(\"LANDVAL\", \"std\"),\n",
        "   \n",
        "    MIN_TOTALVAL=(\"MASMT\", \"min\"), \n",
        "    MAX_TOTALVAL=(\"MASMT\", \"max\"), \n",
        "    MEAN_TOTALVAL=(\"MASMT\", \"mean\"), \n",
        "    MED_TOTALVAL=(\"MASMT\", \"median\"), \n",
        "    SD_TOTALVAL=(\"MASMT\", \"std\"),\n",
        "    \n",
        "    MIN_R2=(\"R2\", \"min\"), \n",
        "    MAX_R2=(\"R2\", \"max\"), \n",
        "    MEAN_R2=(\"R2\", \"mean\"), \n",
        "    MED_R2=(\"R2\", \"median\"), \n",
        "    SD_R2=(\"R2\", \"std\")\n",
        "    \n",
        ").reset_index()\n",
        "\n",
        "# Display summary statistics\n",
        "print(actnbhd_summary)\n",
        "\n",
        "# Write to Excel as needed\n",
        "#actnbhd_summary.to_excel(\"Analysis/actnbhd_summary.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subset NBHDS for Clustering \n",
        "Can be on median MASMT, median R2, or other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clustering_data = actnbhd_summary[[\"MED_TOTALVAL\"]].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and Scale Siholuettes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "clustering_data_scaled = scaler.fit_transform(clustering_data)\n",
        "\n",
        "# Compute the distance matrix\n",
        "dist_matrix = squareform(pdist(clustering_data_scaled, metric='euclidean'))\n",
        "\n",
        "# Perform hierarchical clustering using Ward's method\n",
        "hc = linkage(clustering_data_scaled, method='ward')\n",
        "\n",
        "# Plot silhouette scores for optimal cluster selection\n",
        "silhouette_scores = []\n",
        "for k in range(2, 11):  # Test cluster sizes from 2 to 10\n",
        "    clusters = fcluster(hc, k, criterion='maxclust')\n",
        "    score = silhouette_score(clustering_data_scaled, clusters)\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(2, 11), silhouette_scores, marker='o')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Method for Optimal Clusters')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Cluster Dendrograms for Potential NGROUP Clusters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(hc)\n",
        "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find the optimal number of NGROUP Clusters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Determine the number of clusters for different heights\n",
        "for h in range(1, 10):\n",
        "    clusters = fcluster(hc, h, criterion='distance')\n",
        "    print(f\"Height: {h} - Number of clusters: {len(set(clusters))}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Replot Dendrogram with Visual Dividers\n",
        "Dividers at h = 3 (k=5) and h=6 (k=3) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(hc)\n",
        "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.axhline(y=3, color='red', linestyle='--')  # threshold for clustering\n",
        "plt.axhline(y=5, color='green', linestyle='--')  #threshold for clustering\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cut into K Clusters and assign to NBHD dataset\n",
        "Cutting into 5 clusters (h=3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "actclust_df = (\n",
        "    actnbhd_summary\n",
        "      .copy()\n",
        ")\n",
        "\n",
        "# Assign clusters to the Aggregated dataset\n",
        "actclust_df[\"nbhd_clust3\"] = fcluster(hc, 3, criterion='distance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Join new Clusters to Original Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ngroup_df = (\n",
        "    moddatgwr_df\n",
        "        .merge(\n",
        "            actclust_df[['NBHD', 'nbhd_clust3']],  # limit cols before merge\n",
        "            on='NBHD',\n",
        "            how='left'\n",
        "        )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summaries on the new NGROUP Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute summary statistics by cluster\n",
        "ngroup_summary = ngroup_df.groupby(\"nbhd_clust3\").agg(\n",
        "    n=(\"LANDVAL\", \"count\"),\n",
        "    \n",
        "    MIN_LOCF=(\"LOCF\", \"min\"), \n",
        "    MAX_LOCF=(\"LOCF\", \"max\"), \n",
        "    MEAN_LOCF=(\"LOCF\", \"mean\"), \n",
        "    MED_LOCF=(\"LOCF\", \"median\"), \n",
        "    SD_LOCF=(\"LOCF\", \"std\"),\n",
        "    \n",
        "    MIN_LND=(\"LANDVAL\", \"min\"), \n",
        "    MAX_LND=(\"LANDVAL\", \"max\"), \n",
        "    MEAN_LND=(\"LANDVAL\", \"mean\"), \n",
        "    MED_LND=(\"LANDVAL\", \"median\"), \n",
        "    SD_LND=(\"LANDVAL\", \"std\"),\n",
        "   \n",
        "    MIN_TOTALVAL=(\"MASMT\", \"min\"), \n",
        "    MAX_TOTALVAL=(\"MASMT\", \"max\"), \n",
        "    MEAN_TOTALVAL=(\"MASMT\", \"mean\"), \n",
        "    MED_TOTALVAL=(\"MASMT\", \"median\"), \n",
        "    SD_TOTALVAL=(\"MASMT\", \"std\"),\n",
        "    \n",
        "    MIN_TLA=(\"TLA\", \"min\"), \n",
        "    MAX_TLA=(\"TLA\", \"max\"), \n",
        "    MEAN_TLA=(\"TLA\", \"mean\"), \n",
        "    MED_TLA=(\"TLA\", \"median\"),\n",
        "    \n",
        "    MIN_AGE=(\"ACTAGE\", \"min\"), \n",
        "    MAX_AGE=(\"ACTAGE\", \"max\"), \n",
        "    MEAN_AGE=(\"ACTAGE\", \"mean\"), \n",
        "    MED_AGE=(\"ACTAGE\", \"median\"),\n",
        "\n",
        "    MIN_SEGCLASS=(\"SEGCLASS_NUM\", \"min\"), \n",
        "    MAX_SEGCLASS=(\"SEGCLASS_NUM\", \"max\"), \n",
        "    MEAN_SEGCLASS=(\"SEGCLASS_NUM\", \"mean\"), \n",
        "    MED_SEGCLASS=(\"SEGCLASS_NUM\", \"median\")\n",
        ").reset_index()\n",
        "\n",
        "# Display summary statistics\n",
        "print(ngroup_summary)\n",
        "\n",
        "# Write to Excel as needed\n",
        "#nbhd_summary.to_excel(\"Analysis/nbhd_summary.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Map New NGROUP Clusters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "req_cols = {\"nbhd_clust3\", \"COORDLONGX\", \"COORDLATY\", \"QUICKREFID\"}\n",
        "missing  = req_cols - set(ngroup_df.columns)\n",
        "if missing:\n",
        "    raise KeyError(f\"Missing columns in ngroup_df: {missing}\")\n",
        "\n",
        "plot_df = ngroup_df.dropna(subset=[\"COORDLONGX\", \"COORDLATY\"]).copy()\n",
        "\n",
        "cluster_col = \"nbhd_clust3\"\n",
        "plot_df[cluster_col] = plot_df[cluster_col].astype(str)\n",
        "\n",
        "clusters = sorted(plot_df[cluster_col].unique())\n",
        "if len(clusters) != 5:\n",
        "    raise ValueError(f\"Expected 5 clusters but found {len(clusters)}: {clusters}\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 2  Five-colour categorical palette\n",
        "#    (distinct, colour-blind friendly)\n",
        "# ----------------------------------------------------------\n",
        "palette_hex = [\n",
        "    \"#1b9e77\",  # teal-green\n",
        "    \"#d95f02\",  # orange\n",
        "    \"#7570b3\",  # indigo\n",
        "    \"#e7298a\",  # magenta-pink\n",
        "    \"#66a61e\",  # olive-green\n",
        "]\n",
        "\n",
        "color_lookup = {cl: palette_hex[i] for i, cl in enumerate(clusters)}\n",
        "\n",
        "def colour(cl):\n",
        "    return color_lookup.get(cl, \"#666666\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 3  Create Folium map centred on the data\n",
        "# ----------------------------------------------------------\n",
        "center = [plot_df[\"COORDLATY\"].median(), plot_df[\"COORDLONGX\"].median()]\n",
        "m = folium.Map(location=center, zoom_start=11, tiles=\"OpenStreetMap\")\n",
        "\n",
        "for _, r in plot_df.iterrows():\n",
        "    popup = folium.Popup(\n",
        "        f\"<b>QUICKREFID:</b> {r['QUICKREFID']}<br><b>Cluster:</b> {r[cluster_col]}\",\n",
        "        max_width=250\n",
        "    )\n",
        "    folium.CircleMarker(\n",
        "        [r[\"COORDLATY\"], r[\"COORDLONGX\"]],\n",
        "        radius=5,\n",
        "        color=\"black\", weight=1,\n",
        "        fill=True, fill_opacity=0.85,\n",
        "        fill_color=colour(r[cluster_col]),\n",
        "        popup=popup\n",
        "    ).add_to(m)\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# 4  Add a legend\n",
        "# ----------------------------------------------------------\n",
        "legend_html = (\n",
        "    '<div style=\"position: fixed; bottom: 50px; left: 50px;'\n",
        "    ' background: white; z-index: 9999; font-size: 14px;'\n",
        "    ' border-radius: 8px; padding: 10px; box-shadow: 2px 2px 6px rgba(0,0,0,0.3);\">'\n",
        "    '<b>nbhd_clust3</b><br>'\n",
        ")\n",
        "for cl, col in color_lookup.items():\n",
        "    legend_html += (f'<i style=\"background:{col}; width:12px; height:12px;'\n",
        "                    ' display:inline-block; margin-right:5px;\"></i>'\n",
        "                    f'{cl}<br>')\n",
        "legend_html += '</div>'\n",
        "\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "# Return map → Quarto injects it inline\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/homebrew/Caskroom/miniconda/base/envs/WCADenv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}